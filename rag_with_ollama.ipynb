{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementing RAG for custom data\n",
   "id": "9b338e96306573dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:49:18.109734Z",
     "start_time": "2025-08-24T08:49:10.223312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install pypdf\n",
    "!pip install sentence-transformers\n",
    "!pip install tf-keras\n",
    "!pip install faiss-cpu"
   ],
   "id": "57ed1f53736a87ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (6.0.0)\r\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from pypdf) (4.14.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (5.1.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (1.7.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (0.34.4)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (4.55.4)\r\n",
      "Requirement already satisfied: tqdm in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (4.14.1)\r\n",
      "Requirement already satisfied: Pillow in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (11.3.0)\r\n",
      "Requirement already satisfied: scipy in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sentence-transformers) (2.8.0)\r\n",
      "Requirement already satisfied: requests in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\r\n",
      "Requirement already satisfied: filelock in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.8)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\r\n",
      "Requirement already satisfied: jinja2 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (2.19.0)\r\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tf-keras) (2.19.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.3.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.4)\r\n",
      "Requirement already satisfied: setuptools in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (65.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.14.1)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\r\n",
      "Requirement already satisfied: packaging in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.5)\r\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.74.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\r\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.11.1)\r\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.3)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.14.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.37.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.1.0)\r\n",
      "Requirement already satisfied: namex in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\r\n",
      "Requirement already satisfied: optree in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.17.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.8.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.12.0-cp310-cp310-macosx_14_0_arm64.whl (3.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hRequirement already satisfied: packaging in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from faiss-cpu) (25.0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/ankursaurabh/Downloads/learn/AI/venv/lib/python3.10/site-packages (from faiss-cpu) (2.1.3)\r\n",
      "Installing collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.12.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-24T08:03:33.345187Z",
     "start_time": "2025-08-24T08:03:32.711137Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:05:39.148057Z",
     "start_time": "2025-08-24T08:05:38.525711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pdf_reader = PyPDFLoader(\"ragpaper.pdf\")\n",
    "documents = pdf_reader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "c467d682d61df498",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:49:46.565113Z",
     "start_time": "2025-08-24T08:49:25.143041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating embedding using a free HuggingFace model\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "db = FAISS.from_documents(documents=chunks, embedding=embeddings)"
   ],
   "id": "62e37362a2f0598e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/11/3c9lmb8x2f709848stz2fg2w0000gn/T/ipykernel_4332/2943457944.py:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:02:17.870784Z",
     "start_time": "2025-08-24T09:02:17.811094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing Libraries & Initialize the model\n",
    "from langchain_community.llms import Ollama\n",
    "llm1 = Ollama(model='tinyllama') #with Tinyllama Model\n",
    "llm = Ollama(model='llama3.2') #with llama3.2 Model"
   ],
   "id": "2efde2c289804793",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:02:19.878071Z",
     "start_time": "2025-08-24T09:02:19.851536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\"\"\"Given the following conversation and a follow question, rephrase the follow up question to be a standalone question.\n",
    "                                                        Chat History:{chat_history}\n",
    "                                                        Follow up Input: {question}\n",
    "                                                        Standalone question:\"\"\")\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=llm, retriever=db.as_retriever(), condense_question_prompt=CONDENSE_QUESTION_PROMPT, return_source_documents=True,\n",
    "                                           verbose=False)\n"
   ],
   "id": "8d4551d67c3e0b4c",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:05:27.027238Z",
     "start_time": "2025-08-24T09:05:03.298705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat_history = []\n",
    "query = \"\"\"what are RAG-Token Model?\n",
    "\"\"\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])"
   ],
   "id": "461f867113ea54de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context provided, the RAG-Token Model is a variation of the RAG (Retrieve-and-Generate) model that allows the generator to choose content from several documents when producing an answer. In this model, a different latent document is drawn for each target token, and then marginalized accordingly.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "64f98373f181e1f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
